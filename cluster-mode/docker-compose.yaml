version: '3'

services:
  spark-master:
    image: bitnami/spark:3.5
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - HADOOP_OPTS=-Djava.security.krb5.realm= -Djava.security.krb5.kdc=
      - HADOOP_USER_NAME=root
      - HADOOP_SECURE_DN_USER=root
      - HADOOP_HOME=/opt/bitnami/hadoop
      - HADOOP_CONF_DIR=/opt/bitnami/hadoop/conf
      - SPARK_HADOOP_SECURITY_AUTHENTICATION=simple
      - IVY2_HOME=/tmp/.ivy2
      - SPARK_HOME=/opt/bitnami/spark
      - HOME=/tmp
    volumes:
      - ./data:/data
      - ./ivy_cache:/tmp/.ivy2
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 10s
      timeout: 5s
      retries: 3

  spark-worker-1:
    image: bitnami/spark:3.5
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - HADOOP_OPTS=-Djava.security.krb5.realm= -Djava.security.krb5.kdc=
      - HADOOP_USER_NAME=root
      - HADOOP_SECURE_DN_USER=root
      - HADOOP_HOME=/opt/bitnami/hadoop
      - HADOOP_CONF_DIR=/opt/bitnami/hadoop/conf
      - SPARK_HADOOP_SECURITY_AUTHENTICATION=simple
      - IVY2_HOME=/tmp/.ivy2
      - SPARK_HOME=/opt/bitnami/spark
      - HOME=/tmp
      - SPARK_METRICS_ON=prometheus
    volumes:
      - ./data:/data
      - ./ivy_cache:/tmp/.ivy2

  spark-worker-2:
    image: bitnami/spark:3.5
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8081"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - HADOOP_OPTS=-Djava.security.krb5.realm= -Djava.security.krb5.kdc=
      - HADOOP_USER_NAME=root
      - HADOOP_SECURE_DN_USER=root
      - HADOOP_HOME=/opt/bitnami/hadoop
      - HADOOP_CONF_DIR=/opt/bitnami/hadoop/conf
      - SPARK_HADOOP_SECURITY_AUTHENTICATION=simple
      - IVY2_HOME=/tmp/.ivy2
      - SPARK_HOME=/opt/bitnami/spark
      - HOME=/tmp
      - SPARK_METRICS_ON=prometheus
    volumes:
      - ./data:/data
      - ./ivy_cache:/tmp/.ivy2


  spark-submit:
    image: bitnami/spark:3.5
    container_name: spark-submit
    depends_on:
      spark-master:
        condition: service_healthy
    environment:
      SPARK_MASTER_URL: "spark://spark-master:7077"
    volumes:
      - ./data:/data
      - ./scripts:/scripts
    command: >
      bash -c "
      echo 'Waiting for Spark master...';
      while ! curl -s http://spark-master:8080 | grep -q 'Alive Workers'; do
        sleep 5;
      done;
      echo 'Submitting job...';
      spark-submit
      --master $$SPARK_MASTER_URL
      --deploy-mode client
      --conf spark.jars.ivy=/tmp/.ivy2
      --conf spark.hadoop.fs.defaultFS=file:///
      --name 'NYC Parquet Analysis'
      /scripts/nyc_trip_analysis_parquet.py;
      echo 'Job completed - Container will exist';
      "
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4040"]
      interval: 30s
      timeout: 10s
      retries: 3
  
  spark-analyzer:
    image: bitnami/spark:3.5
    container_name: spark-analyzer
    depends_on:
      spark-submit:
        condition: service_completed_successfully
    environment:
      - SPARK_MODE=client
      - HADOOP_USER_NAME=root
    volumes:
      - ./data:/data
      - ./scripts:/scripts
    command: >
      bash -c "echo 'Starting analysis of output...';
      spark-submit
      --master spark://spark-master:7077
      --deploy-mode client
      --conf spark.jars.ivy=/tmp/.ivy2
      --conf spark.hadoop.fs.defaultFS=file:///
      --name 'NYC Trip Output Analysis'
      /scripts/analyze_output.py;
      echo 'Analysis completed';
      tail -f /dev/null"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4040"]
      interval: 30s
      timeout: 10s
      retries: 3
